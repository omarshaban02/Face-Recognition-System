{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_eigenfaces(images, target_variance=0.9):\n",
    "    print(\"Reshaping images to 1D vectors...\")\n",
    "    num_images = len(images)\n",
    "    image_shape = images[0].shape\n",
    "    image_size = np.prod(image_shape)\n",
    "    flattened_images = images.reshape(num_images, -1)\n",
    "    print(\"Reshaping images complete.\")\n",
    "\n",
    "    print(\"Constructing data matrix...\")\n",
    "    data_matrix = flattened_images.T\n",
    "    print(\"Constructing data matrix complete.\")\n",
    "\n",
    "    print(\"Calculating mean image...\")\n",
    "    mean_image = np.mean(data_matrix, axis=1)\n",
    "    print(\"Mean image calculation complete.\")\n",
    "\n",
    "    print(\"Subtracting mean image from all images...\")\n",
    "    centered_data = data_matrix - mean_image[:, np.newaxis]\n",
    "    print(\"Subtraction complete.\")\n",
    "\n",
    "    print(\"Calculating covariance matrix...\")\n",
    "    covariance_matrix = np.cov(centered_data)\n",
    "    print(\"Covariance matrix calculation complete.\")\n",
    "\n",
    "    print(\"Calculating eigenvalues and eigenvectors...\")\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    print(\"Eigenvalues and eigenvectors calculation complete.\")\n",
    "\n",
    "    print(\"Sorting eigenvectors by eigenvalues...\")\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    print(\"Sorting complete.\")\n",
    "\n",
    "    print(\"Normalizing eigenvectors...\")\n",
    "    normalized_eigenvectors = eigenvectors / np.linalg.norm(eigenvectors, axis=0)\n",
    "    print(\"Normalization complete.\")\n",
    "\n",
    "    print(\"Calculating cumulative explained variance ratio...\")\n",
    "    explained_variance_ratio = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "    print(\"Calculation complete.\")\n",
    "\n",
    "    print(\"Selecting eigenvectors to achieve target variance...\")\n",
    "    num_components = np.argmax(explained_variance_ratio >= target_variance) + 1\n",
    "    selected_eigenvectors = normalized_eigenvectors[:, :num_components]\n",
    "    print(\"Selection complete.\")\n",
    "\n",
    "    print(\"Mapping all images to new components...\")\n",
    "    transformed_data = np.dot(selected_eigenvectors.T, centered_data)\n",
    "    print(\"Mapping complete.\")\n",
    "\n",
    "    return transformed_data, selected_eigenvectors, mean_image\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'images' is a numpy array of shape (num_images, height, width) containing grayscale images\n",
    "# transformed_data, eigenfaces, mean_image = pca_eigenfaces(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"splitted_dataset/train\"\n",
    "images_labels = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
    "\n",
    "images = np.array([cv2.resize(cv2.imread(train_dir + \"/\" + i, cv2.IMREAD_GRAYSCALE), (90, 90)) for i in images_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 90, 90)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping images to 1D vectors...\n",
      "Reshaping images complete.\n",
      "Constructing data matrix...\n",
      "Constructing data matrix complete.\n",
      "Calculating mean image...\n",
      "Mean image calculation complete.\n",
      "Subtracting mean image from all images...\n",
      "Subtraction complete.\n",
      "Calculating covariance matrix...\n",
      "Covariance matrix calculation complete.\n",
      "Calculating eigenvalues and eigenvectors...\n",
      "Eigenvalues and eigenvectors calculation complete.\n",
      "Sorting eigenvectors by eigenvalues...\n",
      "Sorting complete.\n",
      "Normalizing eigenvectors...\n",
      "Normalization complete.\n",
      "Calculating cumulative explained variance ratio...\n",
      "Calculation complete.\n",
      "Selecting eigenvectors to achieve target variance...\n",
      "Selection complete.\n",
      "Mapping all images to new components...\n",
      "Mapping complete.\n"
     ]
    }
   ],
   "source": [
    "transformed_data, eigenfaces, mean_image = pca_eigenfaces(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pca_model(transformed_data, selected_eigenvectors, mean_image, save_folder):\n",
    "    # Save transformed data\n",
    "    np.save(os.path.join(save_folder, 'transformed_data.npy'), transformed_data)\n",
    "\n",
    "    # Save selected eigenvectors\n",
    "    np.save(os.path.join(save_folder, 'selected_eigenvectors.npy'),\n",
    "            selected_eigenvectors)\n",
    "\n",
    "    # Save mean image\n",
    "    np.save(os.path.join(save_folder, 'mean_image.npy'), mean_image)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Save the PCA model\n",
    "save_folder = \"./saved_model\"\n",
    "save_pca_model(transformed_data, eigenfaces, mean_image, save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pca_model(load_folder):\n",
    "    # Load transformed data\n",
    "    transformed_data = np.load(os.path.join(\n",
    "        load_folder, 'transformed_data.npy'))\n",
    "\n",
    "    # Load selected eigenvectors\n",
    "    selected_eigenvectors = np.load(os.path.join(\n",
    "        load_folder, 'selected_eigenvectors.npy'))\n",
    "\n",
    "    # Load mean image\n",
    "    mean_image = np.load(os.path.join(load_folder, 'mean_image.npy'))\n",
    "\n",
    "    return transformed_data, selected_eigenvectors, mean_image\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Load the PCA model\n",
    "# load_folder = \"./saved_model\"\n",
    "# transformed_data, selected_eigenvectors, mean_image = load_pca_model(load_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# # Define the path to the folder containing all images\n",
    "# dataset_folder = \"cropped_faces\"\n",
    "\n",
    "# # Define the number of images to select from each subject for testing\n",
    "# num_test_images_per_subject = 4\n",
    "\n",
    "# # Define the number of subjects to exclude randomly\n",
    "# num_excluded_subjects = 10\n",
    "\n",
    "# # Get a list of all images in the dataset folder\n",
    "# images = [f for f in os.listdir(dataset_folder) if os.path.isfile(\n",
    "#     os.path.join(dataset_folder, f))]\n",
    "\n",
    "# # Extract subjects' names from the filenames\n",
    "# subjects = list(set([image.split(\"_\")[0] for image in images]))\n",
    "\n",
    "# # Randomly select subjects to exclude\n",
    "# excluded_subjects = random.sample(\n",
    "#     subjects, min(num_excluded_subjects, len(subjects)))\n",
    "\n",
    "# # Initialize lists to store paths of training and testing images\n",
    "# train_images = []\n",
    "# test_images = []\n",
    "\n",
    "# for image in images:\n",
    "#     sub = image.split[\"_\"][0]\n",
    "\n",
    "\n",
    "# # Iterate over each image\n",
    "# for sub in subjects:\n",
    "#     if sub not in excluded_subjects:\n",
    "#         # sub_images =\n",
    "#         [f'{sub}_0{i}' for i in random.sample(range(1, 10), 4)]\n",
    "#         test_images.extend(tst)\n",
    "#         train_images.extend()\n",
    "#     # Check if the subject is not in the excluded list\n",
    "#     if subject not in excluded_subjects:\n",
    "#         # Randomly select images for testing\n",
    "#         if random.random() < num_test_images_per_subject / len(images):\n",
    "#             test_images.append(image)\n",
    "#         else:\n",
    "#             train_images.append(image)\n",
    "\n",
    "\n",
    "# # # Define the paths for the train and test folders\n",
    "# # train_folder = \"splitted_dataset/train\"\n",
    "# # test_folder = \"splitted_dataset/test\"\n",
    "\n",
    "# # # Create train and test folders if they don't exist\n",
    "# # os.makedirs(train_folder, exist_ok=True)\n",
    "# # os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# # # Copy train images to the train folder\n",
    "# # for image in train_images:\n",
    "# #     src = os.path.join(dataset_folder, image)\n",
    "# #     dst = os.path.join(train_folder, image)\n",
    "# #     shutil.copy(src, dst)\n",
    "\n",
    "# # # Copy test images to the test folder\n",
    "# # for image in test_images:\n",
    "# #     src = os.path.join(dataset_folder, image)\n",
    "# #     dst = os.path.join(test_folder, image)\n",
    "# #     shutil.copy(src, dst)\n",
    "# dataset_folder = \"cropped_faces\"\n",
    "\n",
    "# images = [f for f in os.listdir(dataset_folder) if os.path.isfile(\n",
    "#     os.path.join(dataset_folder, f))]\n",
    "\n",
    "# train = []\n",
    "# test = []\n",
    "# randx = random.sample(range(1, 16), 4)\n",
    "\n",
    "# for i in images:\n",
    "#     if int(i[4:6]) in randx:\n",
    "#         test.append(i)\n",
    "#     else:\n",
    "#         train.append(i)\n",
    "\n",
    "# # Define the paths for the train and test folders\n",
    "# train_folder = \"splitted_dataset/train\"\n",
    "# test_folder = \"splitted_dataset/test\"\n",
    "\n",
    "# # Create train and test folders if they don't exist\n",
    "# os.makedirs(train_folder, exist_ok=True)\n",
    "# os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# # Copy train images to the train folder\n",
    "# for image in train:\n",
    "#     src = os.path.join(dataset_folder, image)\n",
    "#     dst = os.path.join(train_folder, image)\n",
    "#     shutil.copy(src, dst)\n",
    "\n",
    "# # Copy test images to the test folder\n",
    "# for image in test:\n",
    "#     src = os.path.join(dataset_folder, image)\n",
    "#     dst = os.path.join(test_folder, image)\n",
    "#     shutil.copy(src, dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
